---
title: "Benchmarking DE Tests"
author: 
  - "Rance Nault"
  - "Satabdi Saha"
package: "statsDR"
data: "Last updated: April 12, 2021"
output: 
  BiocStyle::html_document:
    toc: true
    toc_float: true
  vignette: >
    %\VignetteIndexEntry{simple example}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---

```{r}
# Load packages
## TODO: Reduce requirements - look for redundancy
suppressPackageStartupMessages({
  library(snseq.stats)
})
```
# DETesting

- List all the tests that are available (ANOVA, KW, WRS, _LRT_linear_, _LRT_multiple_, _ChiSQ_, MAST, Bayes). Describe the italicized ones. Mention that we updated the test (MAST, WRS) to combined all pairwise. These tests can be run using `DETest`.

## LRT_linear
Describe
```{r}
LRT.linear = DETest(sce, method = 'LRT.linear')
head(LRT.linear)
```

## LRT_multiple
```{r}
LRT.multiple = DETest(sce, method = 'LRT.multiple')
head(LRT.multiple)
```

## ChiSQ
```{r}
chi.square = DETest(sce, method = 'CHISQ')
head(chi.square)
```

How to list the options of method #TODO: Check how people do this, if they do. 
```{r}

```


#Last
```{r}
All = DETest(sim, method = 'All') #This will take a long time depending on the amount of genes.
#The output should be a list of dataframes that have a p-value/sig value
names(All)
```

# Benchmarking
1) Extract p-values of all the test
Data.frame, allgenes = row, column = test for all genes that meet a criteria. Make one for each test 

```{r}
significantGenes = getDEGs(sim, All, threshold = 0.05, fc.threshold = 0.4, bayes.threshold = 1/10, pct.expressed = 0.25)
```

2) EXtract 'truth'
```{r}
trueDEGs = TruthFromSim(sim, fc.threshold = 0.4, pct.expressed = 0.25)
```

```{r}
all.genes = rownames(rowData(sim))
truth = as.factor(all.genes %in% trueDEGs$Gene)
names(truth) = all.genes
comparisons = data.frame(truth)
confusions.list = list()
for (test in names(significantGenes)){
  comparisons[,test] = as.factor(all.genes %in% significantGenes[[test]]$Gene)
  conf.mat = caret::confusionMatrix(comparisons[,test], comparisons$truth)$table
  confusions.list[[test]] = reshape2::melt(conf.mat)
  confusions.list[[test]]$tname = test
}
df.confusionMat = do.call(rbind, lapply(confusions.list, as.data.frame))
df.confusionMat[which(df.confusionMat$Reference == TRUE & df.confusionMat$Prediction == TRUE), 'result'] = 'True Positive'
df.confusionMat[which(df.confusionMat$Reference == TRUE & df.confusionMat$Prediction == FALSE), 'result'] = 'False Negative'
df.confusionMat[which(df.confusionMat$Reference == FALSE & df.confusionMat$Prediction == TRUE), 'result'] = 'False Positive'
df.confusionMat[which(df.confusionMat$Reference == FALSE & df.confusionMat$Prediction == FALSE), 'result'] = 'True Negative'
```

```{r fig.width = 7.5, fig.height = 3.8}
ggplot(df.confusionMat, aes(fill = result, y = value, x = tname)) +
  geom_text(aes(label = value), position = position_dodge(width = 1),
            size = 3, vjust = -0.5) +
  geom_bar(position = "dodge", stat = "identity", color = 'black') + 
  #scale_fill_manual(values = c('#e34242', '#c70000', '#58fc5b', '#04cc08')) +
  theme_bw()
```





```{r}
o = runMAST(sim)
```




